{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How py evaluats a call expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-31 16:34:16.228575: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64,/usr/local/cuda-10.1/lib64\n",
      "2022-03-31 16:34:16.228616: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(['stride', 'squat', 'up', 'down'])\n",
    "X_global = np.load('/home/sstc/文档/action_detection/test_2/global_ft.npy') ##(833, 5, 132)\n",
    "X_course = np.load('/home/sstc/文档/action_detection/test_2/global_ft_course.npy') ## (833,)\n",
    "labels = np.load('/home/sstc/文档/action_detection/test_2/global_y.npy') ##(833, 3, 132)\n",
    "\n",
    "Y_global = to_categorical(labels).astype(int)\n",
    "#shape = X_global.shape[1:] ##(833, 5)  5类（4类动作+背景类）\n",
    "\n",
    "X_global = tf.constant(X_global,name='X_global')\n",
    "X_course = tf.constant(X_course,name='X_course')\n",
    "Y_global= tf.constant(Y_global,name='Y_global')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Activity Classifier\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivityClassifier(tf.keras.Model):\n",
    "    def __init__(self,class_num):\n",
    "        super().__init__()\n",
    "        self.class_num = class_num\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100,activation=tf.nn.relu,name='fc-1')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=class_num)\n",
    "\n",
    "    def call(self, input):\n",
    "        x=self.dense1(input)\n",
    "        x=self.dense2(x)\n",
    "        out = tf.nn.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteClassifier(tf.keras.Model):\n",
    "    def __init__(self,class_num):\n",
    "        super().__init__()\n",
    "        self.class_num = class_num\n",
    "        self.lstm1 = tf.keras.layers.LSTMCell(units=64,activation=tf.nn.relu)\n",
    "        self.lstm2 = tf.keras.layers.LSTMCell(units=128,activation=tf.nn.relu)\n",
    "        self.lstm3 = tf.keras.layers.LSTMCell(units=64,activation=tf.nn.relu)\n",
    "        self.dens1 =  tf.keras.layers.LSTMCell(units=100,activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=class_num)\n",
    "\n",
    "    ## call函数需保存\n",
    "    @tf.function\n",
    "    def call(self, input):\n",
    "        x=self.lstm1(input,states=input.shape[1:],return_state=True,return_sequences=True)\n",
    "        x=self.lstm2(x)\n",
    "        x=self.lstm3(x)\n",
    "        x=self.dens1(x)\n",
    "        x=self.dense2(x)\n",
    "        out = tf.nn.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(train_data,train_label, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        num_train_data = train_data.shape[0]\n",
    "        \n",
    "        index = list(np.random.randint(0, num_train_data, batch_size))\n",
    "        return tf.constant(train_data.numpy()[index]), tf.constant(train_label.numpy()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = CompleteClassifier(Y_global.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797,\n",
       "        798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810,\n",
       "        811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823,\n",
       "        824, 825, 826, 827, 828, 829, 830, 831, 832]),)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg_index = np.where(Y_global.numpy()[:,0]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13830/1166309516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_global\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_global\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_categorical_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BabyActionDetection/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1011\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1012\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BabyActionDetection/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/BabyActionDetection/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "num_batches = int(X_global.shape[0]//batch_size*num_epoch)\n",
    "for batch_idx in range (num_batches):\n",
    "    x,y = get_batch(X_global,Y_global,batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = ac(x)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_idx, loss.numpy()))\n",
    "    grads = tape.gradient(loss, ac.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, ac.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 10:21:19.578254: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-01 10:21:19.610970: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2893040000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.800000\n"
     ]
    }
   ],
   "source": [
    "##----------模型评估\n",
    "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(X_global.shape[0]// batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = ac.predict(X_global[start_index: end_index])\n",
    "    sparse_categorical_accuracy.update_state(y_true=Y_global[start_index: end_index], y_pred=y_pred)\n",
    "print(\"test accuracy: %f\" % sparse_categorical_accuracy.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 1) dtype=int32, numpy=array([[1]], dtype=int32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable([[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(1, 3) dtype=int32, numpy=array([[1, 2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Variable([[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load('/home/sstc/文档/action_detection/test_2/MP_Data_untrimmed/{}.npy'.format('VID20220328180027'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 33, 4)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape([137,int(132/4),4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_base = tf.keras.applications.VGG16(input_shape=(33,33,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79550512e+02,  1.79614755e+02, -9.88020510e+01,  0.00000000e+00,\n",
       "       -0.00000000e+00, -1.00000000e-06,  0.00000000e+00, -0.00000000e+00,\n",
       "        1.00000000e-06,  1.76579000e-01, -1.75474000e-01,  2.49841700e+00,\n",
       "        1.77633114e+02, -1.75193166e+02, -3.43171830e+01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.77633114e+02, -1.75193166e+02, -3.43171830e+01,\n",
       "       -1.44552037e+02,  8.58755780e+01, -2.24908490e+01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -1.48147184e+02,  1.75875783e+02,\n",
       "       -1.52071469e+02,  1.43739252e+02, -1.19164171e+02,  1.56483798e+02,\n",
       "       -7.17149110e+01, -4.16932200e+01, -1.24339246e+02, -5.18096830e+01,\n",
       "        3.13945700e+00, -3.23867790e+01, -1.46634366e+02, -1.36761473e+02,\n",
       "       -1.52170422e+02, -1.56064432e+02, -1.72900415e+02,  1.53821221e+02])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "for i in map(lambda x: x.split('_'),list(b['EulerAngle'].values())):\n",
    "    li.extend(i)\n",
    "np.array(li).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.load('/home/sstc/文档/action_detection/test_2/MP_Data/angle/VID20220328180652.npy')\n",
    "b = np.load('/home/sstc/文档/action_detection/test_2/MP_Data/point/VID20220328180652.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_embedding import FullBodyPoseEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = FullBodyPoseEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in vid_name:\n",
    "    point = np.load('/home/sstc/文档/action_detection/test_2/MP_Data/point/{}.npy'.format(vid))\n",
    "    embed_lm = []\n",
    "    for i in range(point.shape[0]):\n",
    "        embed_lm.append(embedder(b[0,:33*4].reshape([33,-1])[:33,:3]).flatten())\n",
    "    embed = np.vstack(embed_lm)\n",
    "    np.save('/home/sstc/文档/action_detection/test_2/MP_Data/embedding/{}.npy'.format(vid),embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in b.shape[0]\n",
    "c = embedder(b[0,:33*4].reshape([33,-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sstc/文档/action_detection/test_2/out/cpp_combine/10',\n",
       " '/home/sstc/文档/action_detection/test_2/out/cpp_combine/5',\n",
       " '/home/sstc/文档/action_detection/test_2/out/cpp_combine/0.8',\n",
       " '/home/sstc/文档/action_detection/test_2/out/cpp_combine/0.2',\n",
       " '/home/sstc/文档/action_detection/test_2/out/cpp_combine/0.5']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/home/sstc/文档/action_detection/test_2/out/cpp_combine/[0-9]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 3)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "point_f = glob.glob('/home/sstc/文档/action_detection/test_2/MP_Data/point/*.npy')\n",
    "angle_f = glob.glob('/home/sstc/文档/action_detection/test_2/MP_Data/angle/*.npy')\n",
    "vid_name = []\n",
    "for vid in point_f:\n",
    "    vid_name.append(vid.replace('.npy','').split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vid in vid_name:\n",
    "    point = np.load('/home/sstc/文档/action_detection/test_2/MP_Data/point/{}.npy'.format(vid))\n",
    "    angle = np.load('/home/sstc/文档/action_detection/test_2/MP_Data/angle/{}.npy'.format(vid))\n",
    "    combine = np.hstack([point,angle])\n",
    "    np.save('/home/sstc/文档/action_detection/test_2/MP_Data/combine/{}.npy'.format(vid),combine)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d241ac3ff933d877089ddcad169f183662314039ef78157ce20debf463a4679e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('BabyActionDetection': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
